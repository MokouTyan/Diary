【2023.01.04】循环神经网络，RNN

### 前言

这段时间又继续开始学习机器学习，重新观看了B站刘老师的视频

[12.循环神经网络（基础篇）](https://www.bilibili.com/video/BV1Y7411d7Ys?p=12&vd_source=d3b20de6fd728a6822df14fa2e26ef8c)

发现以前我是没记录循环神经网络的，现在重新学习一下

### 正文

循环神经网络主要解决了一个序列上的问题，不同于以往我们学习的CNN，它存在一定的序列关系，比如说天气、股市等，今日的数据，乃至明日的预测数据，依赖于前几天的数据

![image-20230104085249369](https://i0.hdslb.com/bfs/album/db9b85f807d3be1c334c1a7adfd49a4514a1a079.png)

右边是左图的展开，其中下面的黄色圆点是每日的特征输入

上面的输出hidden是隐藏层

比如在第二个RNNCell之中，不仅仅有x2和h1的输入，还有上一层RNNCell的输入（隐含了x1和h0）

```
h1=linear(x1,h0)
h2=linear(x2,h1)
...
hn=linear(xn,hn-1)
```

如果存在先验数据，可以作为h0输入进来，维度和h1、h2一样，可以采用CNN等方法，得到h0再输入进来

但是如果没有任何的数据，那可以将一个全0的张量输入

### RNNCell

我们可以看到RNNCell可以由两个线性层构成，但是实际上可以拼成一个线性层，正如下图中w1h+w2x两个线性层相加，实际上就可以拆分成两个矩阵拼起来相乘

![image-20230104092932542](https://i0.hdslb.com/bfs/album/3a1d35ec8bbe70090bd271663bbd52a3ade264d1.png)

可以自己写RNN，也可以用下面一句话直接调用，但是本质上RNN仍然是在linear的基础上进行发展的

```python
cell = torch.nn.RNNCell(input_size=input_size,hidden_size=hidden_size)
```

